# AcousticSegmentation config file

# Common ALIZE Parameters
distribType             			GD  GD, GF...
loadMixtureFileExtension    	
saveMixtureFileExtension    	
loadFeatureFileExtension    		.prm
featureFilesPath		        	./data/prm_39LFCC/
mixtureFilesPath		        	./gmm/
#labelFilesPath                  	# not used here, default 	label used instead, required if some parts of file have not to be proceeded
labelFilesExtension             	.lbl
labelSelectedFrames             	all
addDefaultLabel                 	true
defaultLabel                    	all
saveMixtureFileFormat     			RAW
loadMixtureFileFormat     			RAW	
saveSegServerFileFormat         	RAW
maxLLK                  			200
minLLK                  			-200
bigEndian               			false
loadFeatureFileFormat     			SPRO4
featureServerBufferSize 			ALL_FEATURES
featureServerMask					0-38 
vectSize							39	# to change if different input features
frameLength							0.01
mixtureDistribCount					128
baggedMinimalLength             	1
baggedMaximalLength             	1
verbose								true
verboseLevel 						2
debug								false     
debugLevel							0


# Useful parameters if models are trained during the speaker segmentation process instead using universal background/world model
nbTrainIt							1
initVarianceFlooring				0.5
initVarianceCeiling					10.0
finalVarianceFlooring				0.1
finalVarianceCeiling				10.0
baggedFrameProbability				1.0	
baggedFrameProbabilityInit			0.6 
normalizeModel						false
normalizeClient                 	false


# AcousticSegmentation
saveSegmentationExtension       	.lbl
loadSegmentationExtension       	.lbl
listFileToSegment               	./lst/list.lst
outputFilesPath						./lblAcousticSegmentationWithMusic/

viterbiBufferLength             	30 #minimal number of frames before switching between HMM states (Viterbi decoding)
decodingEpsilon 		 			5 #epsilon parameter used to stop decoding Viterbi iteration before reaching the fixed number of iterations (decision based on comparison between two consecutive segmentation outputs)

MAPAlgo								MAPConst2 # type of method used to apply model adaptation (MAPConst, MAPConst2, MAPOccDep, MAPModelBased, MLLR)
meanAdapt							true # true if model mean adapted
varAdapt							false # true if covariance matrix adapted
weightAdapt							false # true if model weight adapted
MAPRegFactorMean					0 # only if MAPAlgo = (MAPOccDep, MAPModelBased, MLLR)
MAPAlphaMean						1.0 # only if MAPAlgo = (MAPConst, MAPConst2)
transitionMethod		        	Equiprob # (Equiprob, RapConst) Method used to estimate probability transition between HMM states
gammaTransition		        		0.5 (parameter associated with the transition method)
fudge		                		1

classNb								4 # number of acoustic classes used in the segmentation
class1								telephone # model filename (gmm model stored in mixtureFilesPath directory) of the first class
class2								music # model filename for the second one
class3								musicspeech 
class4								speech
class1Length						200 # minimum duration (in frame number) for segments associated with class 1 named before. If it is smaller, the segment is replaced with adjacent labels 
class2Length						100  
class3Length						200
class4Length						200
musicLabel							music

iterationNb							10 # number of iterations for the model adaptation/viterbi decoding process
aggregateSegment					true # if true, adjacent segments associated with the same label are merged

limitClusterDuration				90000 # used specifically with very long speech signal file in order to provide file partitioning proceeded separately (may be useful for speaker diarization applied further). 
